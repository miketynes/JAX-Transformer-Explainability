{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbfacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca68c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/miniconda3/envs/TransformerExplainability/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import flax\n",
    "import flax.linen as fnn\n",
    "import numpy as np\n",
    "from typing import Callable, Optional, Tuple, Union, Sequence, Iterable\n",
    "\n",
    "sys.path.append(\"../bert\")\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "import modeling_flax_bert as bert_layers\n",
    "import bert_explainability_layers as ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecf52df-6cf7-493b-b2f2-5ebe65e8c9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Add',\n",
       " 'Callable',\n",
       " 'Dense',\n",
       " 'Dropout',\n",
       " 'GeLU',\n",
       " 'IndexSelect',\n",
       " 'LayerNorm',\n",
       " 'MatMul',\n",
       " 'Optional',\n",
       " 'ReLU',\n",
       " 'RelProp',\n",
       " 'RelPropSimple',\n",
       " 'Softmax',\n",
       " 'Tanh',\n",
       " 'Tuple',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'einsum',\n",
       " 'flax',\n",
       " 'jax',\n",
       " 'jnp',\n",
       " 'lax',\n",
       " 'nn',\n",
       " 'np',\n",
       " 'safe_divide']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66d157c-1a63-4fc3-8fbc-074cd1950025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACT2FN',\n",
       " 'BERT_INPUTS_DOCSTRING',\n",
       " 'BERT_START_DOCSTRING',\n",
       " 'BertConfig',\n",
       " 'Callable',\n",
       " 'FLAX_BERT_FOR_NEXT_SENT_PRED_DOCSTRING',\n",
       " 'FLAX_BERT_FOR_PRETRAINING_DOCSTRING',\n",
       " 'FlaxBaseModelOutputWithPastAndCrossAttentions',\n",
       " 'FlaxBaseModelOutputWithPooling',\n",
       " 'FlaxBaseModelOutputWithPoolingAndCrossAttentions',\n",
       " 'FlaxBertAttention',\n",
       " 'FlaxBertEmbeddings',\n",
       " 'FlaxBertEncoder',\n",
       " 'FlaxBertForCausalLM',\n",
       " 'FlaxBertForCausalLMModule',\n",
       " 'FlaxBertForMaskedLM',\n",
       " 'FlaxBertForMaskedLMModule',\n",
       " 'FlaxBertForMultipleChoice',\n",
       " 'FlaxBertForMultipleChoiceModule',\n",
       " 'FlaxBertForNextSentencePrediction',\n",
       " 'FlaxBertForNextSentencePredictionModule',\n",
       " 'FlaxBertForPreTraining',\n",
       " 'FlaxBertForPreTrainingModule',\n",
       " 'FlaxBertForPreTrainingOutput',\n",
       " 'FlaxBertForQuestionAnswering',\n",
       " 'FlaxBertForQuestionAnsweringModule',\n",
       " 'FlaxBertForSequenceClassification',\n",
       " 'FlaxBertForSequenceClassificationModule',\n",
       " 'FlaxBertForTokenClassification',\n",
       " 'FlaxBertForTokenClassificationModule',\n",
       " 'FlaxBertIntermediate',\n",
       " 'FlaxBertLMPredictionHead',\n",
       " 'FlaxBertLayer',\n",
       " 'FlaxBertLayerCollection',\n",
       " 'FlaxBertModel',\n",
       " 'FlaxBertModule',\n",
       " 'FlaxBertOnlyMLMHead',\n",
       " 'FlaxBertOnlyNSPHead',\n",
       " 'FlaxBertOutput',\n",
       " 'FlaxBertPooler',\n",
       " 'FlaxBertPreTrainedModel',\n",
       " 'FlaxBertPreTrainingHeads',\n",
       " 'FlaxBertPredictionHeadTransform',\n",
       " 'FlaxBertSelfAttention',\n",
       " 'FlaxBertSelfOutput',\n",
       " 'FlaxCausalLMOutputWithCrossAttentions',\n",
       " 'FlaxMaskedLMOutput',\n",
       " 'FlaxMultipleChoiceModelOutput',\n",
       " 'FlaxNextSentencePredictorOutput',\n",
       " 'FlaxPreTrainedModel',\n",
       " 'FlaxQuestionAnsweringModelOutput',\n",
       " 'FlaxSequenceClassifierOutput',\n",
       " 'FlaxTokenClassifierOutput',\n",
       " 'FrozenDict',\n",
       " 'ModelOutput',\n",
       " 'Optional',\n",
       " 'Tuple',\n",
       " '_CHECKPOINT_FOR_DOC',\n",
       " '_CONFIG_FOR_DOC',\n",
       " '_TOKENIZER_FOR_DOC',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'add_start_docstrings',\n",
       " 'add_start_docstrings_to_model_forward',\n",
       " 'append_call_sample_docstring',\n",
       " 'append_replace_return_docstrings',\n",
       " 'combine_masks',\n",
       " 'dot_product_attention_weights',\n",
       " 'flatten_dict',\n",
       " 'flax',\n",
       " 'freeze',\n",
       " 'jax',\n",
       " 'jnp',\n",
       " 'lax',\n",
       " 'logger',\n",
       " 'logging',\n",
       " 'make_causal_mask',\n",
       " 'nn',\n",
       " 'nn_partitioning',\n",
       " 'np',\n",
       " 'ours',\n",
       " 'overwrite_call_docstring',\n",
       " 'remat',\n",
       " 'unflatten_dict',\n",
       " 'unfreeze',\n",
       " 'value_and_grad']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(bert_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b957c72-ce2d-4652-b8d3-913977aa9535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c49be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    den = b.clamp(min=1e-9) + b.clamp(max=1e-9)\n",
    "    den = den + den.eq(0).type(den.type()) * 1e-9\n",
    "    return a / den * b.ne(0).type(b.type())\n",
    "\n",
    "\n",
    "def forward_hook(self, input, output):\n",
    "    if type(input[0]) in (list, tuple):\n",
    "        self.X = []\n",
    "        for i in input[0]:\n",
    "            x = i.detach()\n",
    "            x.requires_grad = True\n",
    "            self.X.append(x)\n",
    "    else:\n",
    "        self.X = input[0].detach()\n",
    "        self.X.requires_grad = True\n",
    "\n",
    "    self.Y = output\n",
    "\n",
    "\n",
    "class RelProp(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelProp, self).__init__()\n",
    "        # if not self.training:\n",
    "        self.register_forward_hook(forward_hook)\n",
    "\n",
    "    def gradprop(self, Z, X, S):\n",
    "        C = torch.autograd.grad(Z, X, S, retain_graph=True)\n",
    "        return C\n",
    "\n",
    "    def relprop(self, R, alpha):\n",
    "        return R\n",
    "\n",
    "\n",
    "class RelPropSimple(RelProp):\n",
    "    def relprop(self, R, alpha):\n",
    "        Z = self.forward(self.X)\n",
    "        S = safe_divide(R, Z)\n",
    "        C = self.gradprop(Z, self.X, S)\n",
    "\n",
    "        if torch.is_tensor(self.X) == False:\n",
    "            outputs = []\n",
    "            outputs.append(self.X[0] * C[0])\n",
    "            outputs.append(self.X[1] * C[1])\n",
    "        else:\n",
    "            outputs = self.X * (C[0])\n",
    "        return outputs\n",
    "\n",
    "class MatMul(RelPropSimple):\n",
    "    def forward(self, inputs):\n",
    "        return torch.matmul(*inputs)\n",
    "    \n",
    "class Add(RelPropSimple):\n",
    "    def forward(self, inputs):\n",
    "        return torch.add(*inputs)\n",
    "\n",
    "    def relprop(self, R, alpha):\n",
    "        Z = self.forward(self.X)\n",
    "        S = safe_divide(R, Z)\n",
    "        C = self.gradprop(Z, self.X, S)\n",
    "\n",
    "        a = self.X[0] * C[0]\n",
    "        b = self.X[1] * C[1]\n",
    "\n",
    "        a_sum = a.sum()\n",
    "        b_sum = b.sum()\n",
    "\n",
    "        a_fact = safe_divide(a_sum.abs(), a_sum.abs() + b_sum.abs()) * R.sum()\n",
    "        b_fact = safe_divide(b_sum.abs(), a_sum.abs() + b_sum.abs()) * R.sum()\n",
    "\n",
    "        a = a * safe_divide(a_fact, a.sum())\n",
    "        b = b * safe_divide(b_fact, b.sum())\n",
    "\n",
    "        outputs = [a, b]\n",
    "        return outputs\n",
    "    \n",
    "class IndexSelect(RelProp):\n",
    "    def forward(self, inputs, dim, indices):\n",
    "        self.__setattr__('dim', dim)\n",
    "        self.__setattr__('indices', indices)\n",
    "\n",
    "        return torch.index_select(inputs, dim, indices)\n",
    "\n",
    "    def relprop(self, R, alpha):\n",
    "        Z = self.forward(self.X, self.dim, self.indices)\n",
    "        S = safe_divide(R, Z)\n",
    "        C = self.gradprop(Z, self.X, S)\n",
    "\n",
    "        if torch.is_tensor(self.X) == False:\n",
    "            outputs = []\n",
    "            outputs.append(self.X[0] * C[0])\n",
    "            outputs.append(self.X[1] * C[1])\n",
    "        else:\n",
    "            outputs = self.X * (C[0])\n",
    "        return outputs\n",
    "    \n",
    "class Clone(RelProp):\n",
    "    def forward(self, input, num):\n",
    "        self.__setattr__('num', num)\n",
    "        outputs = []\n",
    "        for _ in range(num):\n",
    "            outputs.append(input)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def relprop(self, R, alpha):\n",
    "        Z = []\n",
    "        for _ in range(self.num):\n",
    "            Z.append(self.X)\n",
    "        S = [safe_divide(r, z) for r, z in zip(R, Z)]\n",
    "        C = self.gradprop(Z, self.X, S)[0]\n",
    "\n",
    "        R = self.X * C\n",
    "\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8424b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones((2,2))\n",
    "B = torch.tensor([[-2., 1], [1, -2]])\n",
    "\n",
    "mm = MatMul()\n",
    "mm([A,B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b922586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 2., -1.],\n",
       "         [ 0.,  0.]], grad_fn=<MulBackward0>),\n",
       " tensor([[ 2.,  0.],\n",
       "         [-1., -0.]], grad_fn=<MulBackward0>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.relprop(torch.tensor([[1.,0],[0,0]]), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b4854b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  2.],\n",
       "        [ 2., -1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add = Add()\n",
    "add([A,B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7f8981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3333, -0.0000],\n",
       "         [-0.0000, 0.0000]], grad_fn=<MulBackward0>),\n",
       " tensor([[0.6667, 0.0000],\n",
       "         [0.0000, 0.0000]], grad_fn=<MulBackward0>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.relprop(torch.tensor([[1.,0],[0,0]]), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c61ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = IndexSelect()\n",
    "pool(B, 1, torch.zeros(1, dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4c7b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., -0.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.relprop(torch.tensor([[1.],[0]]), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a67bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-2.,  1.],\n",
       "         [ 1., -2.]]),\n",
       " tensor([[-2.,  1.],\n",
       "         [ 1., -2.]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = Clone()\n",
    "clone(B, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87014753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.7500],\n",
       "        [0.2500, 0.5000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.relprop([torch.tensor([[.5,.5],[0,0]]), torch.tensor([[0,.25],[.25,.5]])], alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935164c",
   "metadata": {},
   "source": [
    "It looks like clone is necessary because of the way pyTorch tracks gradients. Working out the math, I think the relprop works out to a sum over all of the relevances (which intuitively also makes sense). For this reason, I didn't include \"clone\" in the Flax layers I implemented and whenever I saw a clone.relprop in the pyTorch version, I added the relevances in the Jax version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bd099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-1., -1.],\n",
       "             [-1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = jnp.ones((2,2))\n",
    "B = jnp.array([[-2., 1], [1, -2]])\n",
    "\n",
    "jmm = ours.MatMul()\n",
    "jmm(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72fbce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[ 2., -1.],\n",
       "              [ 0.,  0.]], dtype=float32),\n",
       " DeviceArray([[ 2.,  0.],\n",
       "              [-1., -0.]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jmm.relprop(jnp.array([[1.,0],[0,0]]), A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bee406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-1.,  2.],\n",
       "             [ 2., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_add = ours.Add()\n",
    "j_add(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f4fc5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[ 0.33333334, -0.        ],\n",
       "              [-0.        ,  0.        ]], dtype=float32),\n",
       " DeviceArray([[0.6666667, 0.       ],\n",
       "              [0.       , 0.       ]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_add.relprop(jnp.array([[1.,0],[0,0]]), A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139425a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-2.],\n",
       "             [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_pool = ours.IndexSelect()\n",
    "jax_pool(B, 1, jnp.zeros(1, dtype=jnp.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154ae920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 1.,  0.],\n",
       "             [ 0., -0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_pool.relprop(jnp.array([[1.],[0]]), B, 1, jnp.zeros(1, dtype=jnp.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3942e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenDict({\n",
      "    kernel: DeviceArray([[ 1.53342038e-01,  3.29581231e-01],\n",
      "                 [ 4.70121145e-01,  1.81581691e-01],\n",
      "                 [ 1.80420190e-01,  3.35969597e-01],\n",
      "                 [-1.62113383e-01, -2.02395543e-01],\n",
      "                 [-1.18919984e-01, -6.62900805e-02],\n",
      "                 [-4.10243064e-01,  7.33509436e-02],\n",
      "                 [ 4.96547073e-02, -2.71931272e-02],\n",
      "                 [-2.19073966e-01,  4.65010494e-01],\n",
      "                 [ 1.54693127e-02,  1.10250756e-01],\n",
      "                 [-3.89764100e-01,  8.84109288e-02],\n",
      "                 [-3.79199862e-01, -2.35682800e-02],\n",
      "                 [ 3.24670374e-01,  2.04515398e-01],\n",
      "                 [ 1.44210760e-04,  1.65998340e-01],\n",
      "                 [-3.36234242e-01, -3.94779295e-01],\n",
      "                 [-1.40488684e-01, -5.03639765e-02],\n",
      "                 [-2.11226270e-02,  2.08313853e-01],\n",
      "                 [ 9.56470072e-02,  2.05471292e-01],\n",
      "                 [-9.69679356e-02, -3.74182016e-01],\n",
      "                 [-3.60750526e-01,  1.26213387e-01],\n",
      "                 [-1.55270472e-01,  3.00449669e-01]], dtype=float32),\n",
      "    bias: DeviceArray([0., 0.], dtype=float32),\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "jax_dense = ours.Dense(2)\n",
    "x = jnp.ones((1,20))\n",
    "variables = jax_dense.init(jax.random.PRNGKey(0), x)\n",
    "model = jax_dense.bind(variables)\n",
    "model(x)\n",
    "variables\n",
    "print(model.variables[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92569ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1.1891876e-01, 3.6458510e-01, 1.3991822e-01, 0.0000000e+00,\n",
       "              0.0000000e+00, 0.0000000e+00, 3.8507875e-02, 0.0000000e+00,\n",
       "              1.1996655e-02, 0.0000000e+00, 0.0000000e+00, 2.5178614e-01,\n",
       "              1.1183733e-04, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "              7.4175507e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],            dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.relprop(jnp.array([[1.,0]]), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a164535",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "configuration = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d36f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello world!\")\n",
    "input_ids = jnp.array(inputs[\"input_ids\"])\n",
    "token_ids = jnp.array(inputs[\"token_type_ids\"])\n",
    "attention_mask = jnp.array(inputs[\"attention_mask\"])\n",
    "position_ids = jnp.arange(input_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f5da0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = bert_layers.FlaxBertEmbeddings(configuration)\n",
    "variables = embedding_layer.init(jax.random.PRNGKey(0), input_ids, token_ids,  position_ids, attention_mask)\n",
    "output = embedding_layer.apply(variables, input_ids, token_ids, position_ids, attention_mask)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "061703bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[ 1.47529153e-08, -2.83236457e-08, -2.98519609e-08, ...,\n",
       "               -9.80268879e-08,  3.19056568e-08, -4.26698819e-08],\n",
       "              [ 2.07204494e-08,  2.83888308e-08,  2.44977816e-08, ...,\n",
       "               -7.83912455e-08, -5.39528457e-08,  3.94658128e-09],\n",
       "              [ 2.63997428e-08,  2.46574903e-08,  3.82257674e-08, ...,\n",
       "               -5.37965015e-08, -3.58449519e-08,  1.20567904e-07],\n",
       "              [-1.14016965e-08, -6.57746302e-09, -1.69149015e-08, ...,\n",
       "               -5.53824497e-09, -6.18229024e-08, -3.85396532e-08],\n",
       "              [-7.03338898e-09,  2.34075426e-08,  4.81068483e-08, ...,\n",
       "               -3.22811111e-08, -4.31609166e-08, -5.09730675e-08]],            dtype=float32),\n",
       " DeviceArray([[-1.8991523e-08,  1.8220303e-08,  3.6113799e-09, ...,\n",
       "               -9.9331722e-08, -3.6784922e-08,  3.1697240e-08],\n",
       "              [-3.8814896e-08, -3.0151741e-09,  6.9854250e-10, ...,\n",
       "                7.1177952e-09,  8.2972127e-09, -2.5059039e-08],\n",
       "              [ 3.0709678e-08,  6.5667112e-09,  2.8606214e-08, ...,\n",
       "               -9.3753565e-09, -1.5138864e-08,  1.2108156e-07],\n",
       "              [ 4.5753099e-09,  6.1042137e-08,  1.9904721e-08, ...,\n",
       "               -2.9699454e-08, -2.2170410e-08,  1.6341151e-08],\n",
       "              [ 6.3438228e-09,  1.7615813e-08,  1.5376797e-08, ...,\n",
       "               -2.5473739e-08,  2.2812076e-08,  1.2390626e-09]],            dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = jnp.array(np.random.rand(*output.shape))\n",
    "cam = cam / cam.sum()\n",
    "cam = embedding_layer.apply(variables, output, input_ids, token_ids, position_ids, attention_mask, method=embedding_layer.relprop)\n",
    "cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8f81f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[jnp.newaxis]\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7f72b63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attention = bert_layers.FlaxBertAttention(configuration)\n",
    "variables = attention.init(jax.random.PRNGKey(0), output, attention_mask, None)\n",
    "hidden_states = attention.apply(variables, output, attention_mask, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "def523a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DeviceArray([[[-0.5629446 ,  1.0679047 ,  1.1388767 , ...,  0.3926163 ,\n",
      "               -1.4752828 ,  1.9199177 ],\n",
      "              [-1.1342765 , -0.7030668 , -0.18691306, ...,  2.3455682 ,\n",
      "                1.5618546 , -0.4823021 ],\n",
      "              [ 0.35637692, -0.3917392 ,  0.12976551, ...,  1.4595735 ,\n",
      "                0.59808064,  0.1932004 ],\n",
      "              [ 0.6631112 ,  1.5822634 ,  1.1960372 , ..., -0.13444664,\n",
      "                1.0535946 ,  1.4545076 ],\n",
      "              [ 0.5495985 , -0.10840818, -0.42316666, ...,  0.59822196,\n",
      "                1.625095  ,  1.389647  ]]], dtype=float32),)\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6deaa841",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[1.8484204e-04, 2.5492642e-04, 7.8359575e-05, ...,\n",
       "               9.8414523e-05, 5.9304934e-05, 3.1589242e-04],\n",
       "              [2.4367780e-04, 4.8970850e-04, 4.8835133e-04, ...,\n",
       "               1.4320457e-04, 2.2933554e-04, 3.5219468e-04],\n",
       "              [3.0232969e-04, 1.6612618e-04, 2.3883308e-04, ...,\n",
       "               1.3362999e-04, 1.8775632e-04, 1.7151897e-04],\n",
       "              [2.6469497e-04, 4.4329997e-04, 4.1071716e-04, ...,\n",
       "               4.3890130e-04, 4.1915450e-04, 4.6043098e-04],\n",
       "              [1.0859840e-04, 1.6374406e-04, 2.7995577e-04, ...,\n",
       "               2.0164947e-04, 4.1660364e-04, 3.2140972e-04]]],            dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = jnp.array(np.random.rand(*hidden_states[0].shape))\n",
    "cam = cam / cam.sum()\n",
    "cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c120e35f-9713-447c-b743-605b62cf4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e780d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InconclusiveDimensionOperation",
     "evalue": "Cannot divide evenly the sizes of shapes (5, 768) and (5, 768, 12, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInconclusiveDimensionOperation\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cam \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cam\u001b[38;5;241m.\u001b[39msum()\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/repos/JAX-Transformer-Explainability/nb/../bert/modeling_flax_bert.py:673\u001b[0m, in \u001b[0;36mFlaxBertAttention.relprop\u001b[0;34m(self, cam, hidden_states, attention_mask, layer_head_mask, key_value_states, init_cache, deterministic, output_attentions)\u001b[0m\n\u001b[1;32m    671\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    672\u001b[0m (cam1, cam2) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mrelprop(cam, attn_output, hidden_states, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[0;32m--> 673\u001b[0m cam1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelprop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcam1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m##TODO: Check that addition works for all clone inputs?\u001b[39;00m\n\u001b[1;32m    685\u001b[0m cam_sum \u001b[38;5;241m=\u001b[39m cam1\u001b[38;5;241m+\u001b[39mcam2\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/repos/JAX-Transformer-Explainability/nb/../bert/modeling_flax_bert.py:559\u001b[0m, in \u001b[0;36mFlaxBertSelfAttention.relprop\u001b[0;34m(self, cam, hidden_states, attention_mask, layer_head_mask, key_value_states, init_cache, deterministic, output_attentions)\u001b[0m\n\u001b[1;32m    556\u001b[0m     cam1_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;241m.\u001b[39mrelprop(cam1_2, hidden_states)\n\u001b[1;32m    557\u001b[0m     cam2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mrelprop(cam2, hidden_states)\n\u001b[0;32m--> 559\u001b[0m attn_grad \u001b[38;5;241m=\u001b[39m \u001b[43mvgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# gradient w.r.t. hidden states. Is this right?\u001b[39;49;00m\n\u001b[1;32m    560\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minit_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m## TODO:Check addition is same as clone?\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/JAX-Transformer-Explainability/nb/../bert/modeling_flax_bert.py:75\u001b[0m, in \u001b[0;36mvgrad\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvgrad\u001b[39m(f, x):\n\u001b[0;32m---> 75\u001b[0m   y, vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m vjp_fn(jnp\u001b[38;5;241m.\u001b[39mones(y\u001b[38;5;241m.\u001b[39mshape))[\u001b[38;5;241m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/repos/JAX-Transformer-Explainability/nb/../bert/modeling_flax_bert.py:559\u001b[0m, in \u001b[0;36mFlaxBertSelfAttention.relprop.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    556\u001b[0m     cam1_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;241m.\u001b[39mrelprop(cam1_2, hidden_states)\n\u001b[1;32m    557\u001b[0m     cam2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mrelprop(cam2, hidden_states)\n\u001b[0;32m--> 559\u001b[0m attn_grad \u001b[38;5;241m=\u001b[39m vgrad(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# gradient w.r.t. hidden states. Is this right?\u001b[39;49;00m\n\u001b[1;32m    560\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minit_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    566\u001b[0m                   hidden_states[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m## TODO:Check addition is same as clone?\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/repos/JAX-Transformer-Explainability/nb/../bert/modeling_flax_bert.py:365\u001b[0m, in \u001b[0;36mFlaxBertSelfAttention.__call__\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, key_value_states, init_cache, deterministic, output_attentions)\u001b[0m\n\u001b[1;32m    362\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states)\n\u001b[1;32m    363\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states)\n\u001b[0;32m--> 365\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key_states)\n\u001b[1;32m    367\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(value_states)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/repos/JAX-Transformer-Explainability/nb/../bert/modeling_flax_bert.py:300\u001b[0m, in \u001b[0;36mFlaxBertSelfAttention._split_heads\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_heads\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/TransformerExplainability/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:738\u001b[0m, in \u001b[0;36m_reshape\u001b[0;34m(a, order, *args)\u001b[0m\n\u001b[1;32m    736\u001b[0m newshape \u001b[38;5;241m=\u001b[39m _compute_newshape(a, args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m args)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 738\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    740\u001b[0m   dims \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(ndim(a))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 29 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/TransformerExplainability/lib/python3.10/site-packages/jax/core.py:1510\u001b[0m, in \u001b[0;36mDimensionHandler.divide_shape_sizes\u001b[0;34m(self, s1, s2)\u001b[0m\n\u001b[1;32m   1508\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sz1 \u001b[38;5;241m%\u001b[39m sz2:\n\u001b[0;32m-> 1510\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m InconclusiveDimensionOperation(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot divide evenly the sizes of shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(s1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(s2)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sz1 \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m sz2\n",
      "\u001b[0;31mInconclusiveDimensionOperation\u001b[0m: Cannot divide evenly the sizes of shapes (5, 768) and (5, 768, 12, 64)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/mike/miniconda3/envs/TransformerExplainability/lib/python3.10/site-packages/jax/core.py\u001b[0m(1510)\u001b[0;36mdivide_shape_sizes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1508 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1509 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0msz1\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msz2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1510 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0mInconclusiveDimensionOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot divide evenly the sizes of shapes {tuple(s1)} and {tuple(s2)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1511 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0msz1\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0msz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1512 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cam = attention.apply(variables, cam, output, None, None, method=attention.relprop)\n",
    "cam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d643f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = bert_layers.FlaxBertLayer(configuration)\n",
    "variables = layer.init(jax.random.PRNGKey(0), output, attention_mask, None)\n",
    "hidden_states = layer.apply(variables, output, attention_mask, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = jnp.array(np.random.rand(*hidden_states[0].shape))\n",
    "cam = cam / cam.sum()\n",
    "cam = layer.apply(variables, cam, output, attention_mask, None, method=layer.relprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1fb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.shape\n",
    "cam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49688bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_collection = bert_layers.FlaxBertLayerCollection(configuration)\n",
    "variables = layer_collection.init(jax.random.PRNGKey(0), output, attention_mask, None)\n",
    "hidden_states = layer_collection.apply(variables, output, attention_mask, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac611654",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = jnp.array(np.random.rand(*hidden_states[0].shape))\n",
    "cam = cam / cam.sum()\n",
    "cam = layer_collection.apply(variables, cam, output, attention_mask, None, method=layer_collection.relprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = bert_layers.FlaxBertEncoder(configuration)\n",
    "variables = encoder.init(jax.random.PRNGKey(0), output, attention_mask, None)\n",
    "hidden_states = encoder.apply(variables, output, attention_mask, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359601b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = jnp.array(np.random.rand(*hidden_states[0].shape))\n",
    "cam = cam / cam.sum()\n",
    "cam = encoder.apply(variables, cam, output, attention_mask, None, method=encoder.relprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello world!\",])\n",
    "input_ids = jnp.array(inputs[\"input_ids\"])\n",
    "attention_mask = jnp.array(inputs[\"attention_mask\"])\n",
    "print(input_ids.shape)\n",
    "\n",
    "bert_module = bert_layers.FlaxBertModule(configuration)\n",
    "variables = bert_module.init(jax.random.PRNGKey(0), input_ids, attention_mask, None)\n",
    "hidden_states = bert_module.apply(variables, input_ids, attention_mask, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb44158",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = jnp.array(np.random.rand(*hidden_states[1].shape))\n",
    "cam = cam / cam.sum()\n",
    "cam = bert_module.apply(variables, cam, input_ids, attention_mask, None, method=bert_module.relprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0171a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15925ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cam[0] corresponds to position/token-type embeddings and cam[1] corresponds to token embeddings\n",
    "cam[0].sum() + cam[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c58c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello world!\",])\n",
    "input_ids = jnp.array(inputs[\"input_ids\"])\n",
    "token_ids = jnp.array(inputs[\"token_type_ids\"])\n",
    "attention_mask = jnp.array(inputs[\"attention_mask\"])\n",
    "position_ids = jnp.arange(input_ids.shape[0])\n",
    "\n",
    "seq_class_module = bert_layers.FlaxBertForSequenceClassificationModule(configuration)\n",
    "variables = seq_class_module.init(jax.random.PRNGKey(0), input_ids, attention_mask, token_ids, position_ids, None)\n",
    "hidden_states = seq_class_module.apply(variables, input_ids, attention_mask, token_ids, position_ids, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = jnp.array(np.random.rand(*hidden_states[0].shape))\n",
    "cam = cam / cam.sum()\n",
    "print(cam, input_ids.dtype, attention_mask.dtype)\n",
    "cam = seq_class_module.apply(variables, cam, input_ids, attention_mask, token_ids, position_ids, None, method=seq_class_module.relprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a29dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bert_layers.FlaxBertForSequenceClassification(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe44266",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5358efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = jnp.array(np.random.rand(*output[0].shape))\n",
    "model.relprop(cam, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82aa2db-b7a8-45fe-8c62-19e12bf79aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
