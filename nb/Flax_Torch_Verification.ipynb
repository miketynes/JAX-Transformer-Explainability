{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:50:58.855301: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-30 16:50:58.855342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-30 16:50:58.855346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from clu import parameter_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modules needed to be verified\n",
    "\n",
    "\n",
    "## Basic Building Blocks (bb)\n",
    "all the components in the layers file\n",
    "\n",
    "- FlaxBertForSequenceClassification\n",
    "    - FlaxBertForSequenceClassificationModule\n",
    "        - FlaxBertModule\n",
    "            - FlaxBertEmbeddings\n",
    "                - Add\n",
    "                - LayerNorm\n",
    "                - Dropout\n",
    "            - FlaxBertEncoder\n",
    "                - FlaxBertLayerCollection\n",
    "                    - FlaxBertLayer\n",
    "                        - FlaxBertAttention\n",
    "                            - FlaxBertSelfAttention(bb only)\n",
    "                            - FlaxBertSelfOutput(bb only)\n",
    "                        - FlaxBertIntermediate(bb only)\n",
    "                        - FlaxBertOutput(bb only)\n",
    "                    - FlaxBertCheckpointLayer(cond.)\n",
    "            - FlaxBertPooler(bb only)\n",
    "        - Dropout\n",
    "        - Dense"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Building Block verification.\n",
    "- FlaxBertSelfAttention vs.     BertSelfAttention\n",
    "- FlaxBertSelfOutput    vs.     BertSelfOutput\n",
    "- FlaxBertIntermediate  vs.     BertIntermediate\n",
    "- FlaxBertOutput        vs.     BertOutput\n",
    "- FlaxBertPooler        vs.     BertPooler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from bert_torch.BERT import *\n",
    "from bert.modeling_flax_bert import *\n",
    "import bert.modeling_flax_bert as layers\n",
    "from transformers import BertConfig, BertTokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "configuration = BertConfig()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101 7592 2088  999  102]] tensor([[ 101, 7592, 2088,  999,  102]])\n",
      "[0] tensor([0])\n"
     ]
    }
   ],
   "source": [
    "text_batch = [\"Hello world!\"]\n",
    "inputs = tokenizer(text_batch)\n",
    "input_ids = jnp.array(inputs[\"input_ids\"])\n",
    "token_ids = jnp.array(inputs[\"token_type_ids\"])\n",
    "attention_mask = jnp.array(inputs[\"attention_mask\"])\n",
    "position_ids = jnp.arange(input_ids.shape[0])\n",
    "\n",
    "pt_inputs = tokenizer(text_batch, return_tensors='pt')\n",
    "pt_input_ids = pt_inputs[\"input_ids\"]\n",
    "pt_token_ids = pt_inputs[\"token_type_ids\"]\n",
    "pt_attention_mask = pt_inputs[\"attention_mask\"]\n",
    "pt_position_ids = torch.tensor(np.arange(pt_input_ids.shape[0]))\n",
    "\n",
    "print(input_ids, pt_input_ids)\n",
    "print(position_ids, pt_position_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "pt_layer = BertEmbeddings(configuration).eval()\n",
    "f_layer = FlaxBertEmbeddings(configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings.weight torch.Size([30522, 768])\n",
      "position_embeddings.weight torch.Size([512, 768])\n",
      "token_type_embeddings.weight torch.Size([2, 768])\n",
      "LayerNorm.weight torch.Size([768])\n",
      "LayerNorm.bias torch.Size([768])\n",
      "{'params': {'word_embeddings': {'embedding': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.39037085,  0.69918156, -0.43531248, ..., -0.8851334 ,\n",
      "         0.44491395,  1.3068058 ],\n",
      "       [-1.0019616 ,  0.33720052, -0.31363687, ..., -0.12821011,\n",
      "        -1.2826427 , -0.49181524],\n",
      "       ...,\n",
      "       [-0.9476344 ,  0.5520859 , -0.08225149, ..., -0.69733894,\n",
      "         0.6921447 ,  0.8465421 ],\n",
      "       [ 0.76536405,  0.8921807 , -0.6928721 , ...,  1.6470219 ,\n",
      "        -0.19731402, -0.6309815 ],\n",
      "       [-1.5726628 , -1.8801837 , -1.1196718 , ..., -0.9280115 ,\n",
      "        -0.12447178,  0.79312205]], dtype=float32)}, 'position_embeddings': {'embedding': array([[ 9.9745548e-01,  1.4434007e+00,  3.2465394e+00, ...,\n",
      "         1.1698737e+00,  3.0332944e-01,  2.2421880e+00],\n",
      "       [-1.5460092e+00,  1.7768246e+00,  1.3950862e+00, ...,\n",
      "        -1.9740407e+00, -5.6481814e-01, -7.9574150e-01],\n",
      "       [-6.7329925e-01,  9.0494215e-01,  2.3852897e-01, ...,\n",
      "         3.6278033e-01, -5.2145481e-01,  1.4117745e-01],\n",
      "       ...,\n",
      "       [-2.4048376e-01, -9.4907083e-02, -1.0575962e-03, ...,\n",
      "         8.6566709e-02,  9.9622399e-01, -1.1557412e+00],\n",
      "       [-8.5017599e-02, -4.1723940e-01, -1.5939990e+00, ...,\n",
      "        -6.2502468e-01,  3.4456991e-02,  3.1464544e-01],\n",
      "       [-5.8586335e-01,  9.4680357e-01, -7.6762088e-02, ...,\n",
      "         8.5533130e-01, -4.9625555e-01, -2.0017161e+00]], dtype=float32)}, 'token_type_embeddings': {'embedding': array([[ 0.8654805 , -0.79366356,  1.6031009 , ..., -0.8147134 ,\n",
      "        -0.53726494,  1.5780786 ],\n",
      "       [ 0.13776572, -0.5034223 ,  0.09333991, ...,  0.8244487 ,\n",
      "         0.21702327,  0.92173225]], dtype=float32)}, 'LayerNorm': {'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), 'scale': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32)}}}\n"
     ]
    }
   ],
   "source": [
    "for k,v in pt_layer.named_parameters():\n",
    "    print(k, v.shape)\n",
    "\n",
    "vf = {'params':\n",
    "          {'word_embeddings':\n",
    "               {'embedding': None},\n",
    "           'position_embeddings':\n",
    "               {'embedding': None},\n",
    "           'token_type_embeddings':\n",
    "               {'embedding': None},\n",
    "           'LayerNorm':\n",
    "               {'bias': None,\n",
    "                'scale': None},\n",
    "        }\n",
    "      }\n",
    "for k,v in pt_layer.named_parameters():\n",
    "    if k == 'word_embeddings.weight':\n",
    "        vf['params']['word_embeddings']['embedding'] = v.detach().numpy()\n",
    "    if k == 'position_embeddings.weight':\n",
    "        vf['params']['position_embeddings']['embedding'] = v.detach().numpy()\n",
    "    if k == 'token_type_embeddings.weight':\n",
    "        vf['params']['token_type_embeddings']['embedding'] = v.detach().numpy()\n",
    "    if k == 'LayerNorm.weight':\n",
    "        vf['params']['LayerNorm']['scale'] = v.detach().numpy()\n",
    "    if k == 'LayerNorm.bias':\n",
    "        vf['params']['LayerNorm']['bias'] = v.detach().numpy()\n",
    "\n",
    "print(vf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# vf = f_layer.init(jax.random.PRNGKey(0), input_ids, token_ids,  position_ids, attention_mask)\n",
    "f_out = f_layer.apply(vf, input_ids, token_ids, position_ids, attention_mask)\n",
    "pt_out = pt_layer(input_ids=pt_input_ids, token_type_ids=pt_token_ids, position_ids=pt_position_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30522, 768)\n",
      "(1, 5, 768)\n",
      "torch.Size([1, 5, 768])\n",
      "3.368198e-05\n"
     ]
    }
   ],
   "source": [
    "print(vf['params']['word_embeddings']['embedding'].shape)\n",
    "print(f_out.shape)\n",
    "print(pt_out.shape)\n",
    "print(np.abs(pt_out.detach().numpy() - f_out).sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relprop 2\n",
      "2.7899752\n",
      "2.787298\n",
      "2.7194073\n",
      "1.0000002\n",
      "1.0\n",
      "(1, 5, 768)\n"
     ]
    }
   ],
   "source": [
    "cam = np.random.rand(*f_out.shape)\n",
    "f_cam = jnp.array( cam / cam.sum())\n",
    "pt_cam = torch.tensor(cam / cam.sum())\n",
    "\n",
    "f_cam1, f_cam2 = f_layer.apply(vf, f_cam, input_ids, token_ids, position_ids, attention_mask, method=f_layer.relprop)\n",
    "kwargs = {'alpha': 1}\n",
    "pt_cam1, pt_cam2 = pt_layer.relprop(pt_cam, **kwargs)\n",
    "\n",
    "\n",
    "print(np.abs(np.array(f_cam1) - pt_cam1.detach().numpy()).sum())\n",
    "print(np.abs(np.array(f_cam2) - pt_cam2.detach().numpy()).sum())\n",
    "print(np.abs(np.array(f_cam1) - pt_cam2.detach().numpy()).sum())\n",
    "print(np.sum(f_cam1) + np.sum(f_cam2))\n",
    "print(np.sum(pt_cam1.detach().numpy()) + np.sum(pt_cam2.detach().numpy()))\n",
    "print(f_cam2.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+--------------+------------+-----------+-------+\n",
      "| Name                                   | Shape        | Size       | Mean      | Std   |\n",
      "+----------------------------------------+--------------+------------+-----------+-------+\n",
      "| params/LayerNorm/bias                  | (768,)       | 768        | 0.0       | 0.0   |\n",
      "| params/LayerNorm/scale                 | (768,)       | 768        | 1.0       | 0.0   |\n",
      "| params/position_embeddings/embedding   | (512, 768)   | 393,216    | -0.00286  | 0.999 |\n",
      "| params/token_type_embeddings/embedding | (2, 768)     | 1,536      | -0.00341  | 1.01  |\n",
      "| params/word_embeddings/embedding       | (30522, 768) | 23,440,896 | -7.33e-05 | 1.0   |\n",
      "+----------------------------------------+--------------+------------+-----------+-------+\n",
      "Total: 23,837,184\n",
      "BertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (add1): Add()\n",
      "  (add2): Add()\n",
      ") 23837184\n"
     ]
    }
   ],
   "source": [
    "print(parameter_overview.get_parameter_overview(vf))\n",
    "print(pt_layer, count_parameters(pt_layer))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pt_layer = BertEncoder(configuration).eval()\n",
    "f_layer = FlaxBertEncoder(configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.0.attention.self.query.bias torch.Size([768])\n",
      "layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.0.attention.self.key.bias torch.Size([768])\n",
      "layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.0.attention.self.value.bias torch.Size([768])\n",
      "layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.0.attention.output.dense.bias torch.Size([768])\n",
      "layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "layer.0.output.dense.bias torch.Size([768])\n",
      "layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.1.attention.self.query.bias torch.Size([768])\n",
      "layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.1.attention.self.key.bias torch.Size([768])\n",
      "layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.1.attention.self.value.bias torch.Size([768])\n",
      "layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.1.attention.output.dense.bias torch.Size([768])\n",
      "layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "layer.1.output.dense.bias torch.Size([768])\n",
      "layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.2.attention.self.query.bias torch.Size([768])\n",
      "layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.2.attention.self.key.bias torch.Size([768])\n",
      "layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.2.attention.self.value.bias torch.Size([768])\n",
      "layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.2.attention.output.dense.bias torch.Size([768])\n",
      "layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "layer.2.output.dense.bias torch.Size([768])\n",
      "layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.3.attention.self.query.bias torch.Size([768])\n",
      "layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.3.attention.self.key.bias torch.Size([768])\n",
      "layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.3.attention.self.value.bias torch.Size([768])\n",
      "layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.3.attention.output.dense.bias torch.Size([768])\n",
      "layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "layer.3.output.dense.bias torch.Size([768])\n",
      "layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.4.attention.self.query.bias torch.Size([768])\n",
      "layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.4.attention.self.key.bias torch.Size([768])\n",
      "layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.4.attention.self.value.bias torch.Size([768])\n",
      "layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.4.attention.output.dense.bias torch.Size([768])\n",
      "layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "layer.4.output.dense.bias torch.Size([768])\n",
      "layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.5.attention.self.query.bias torch.Size([768])\n",
      "layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.5.attention.self.key.bias torch.Size([768])\n",
      "layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.5.attention.self.value.bias torch.Size([768])\n",
      "layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.5.attention.output.dense.bias torch.Size([768])\n",
      "layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "layer.5.output.dense.bias torch.Size([768])\n",
      "layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.6.attention.self.query.bias torch.Size([768])\n",
      "layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.6.attention.self.key.bias torch.Size([768])\n",
      "layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.6.attention.self.value.bias torch.Size([768])\n",
      "layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.6.attention.output.dense.bias torch.Size([768])\n",
      "layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "layer.6.output.dense.bias torch.Size([768])\n",
      "layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.7.attention.self.query.bias torch.Size([768])\n",
      "layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.7.attention.self.key.bias torch.Size([768])\n",
      "layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.7.attention.self.value.bias torch.Size([768])\n",
      "layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.7.attention.output.dense.bias torch.Size([768])\n",
      "layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "layer.7.output.dense.bias torch.Size([768])\n",
      "layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.8.attention.self.query.bias torch.Size([768])\n",
      "layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.8.attention.self.key.bias torch.Size([768])\n",
      "layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.8.attention.self.value.bias torch.Size([768])\n",
      "layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.8.attention.output.dense.bias torch.Size([768])\n",
      "layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "layer.8.output.dense.bias torch.Size([768])\n",
      "layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.9.attention.self.query.bias torch.Size([768])\n",
      "layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.9.attention.self.key.bias torch.Size([768])\n",
      "layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.9.attention.self.value.bias torch.Size([768])\n",
      "layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.9.attention.output.dense.bias torch.Size([768])\n",
      "layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "layer.9.output.dense.bias torch.Size([768])\n",
      "layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.10.attention.self.query.bias torch.Size([768])\n",
      "layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.10.attention.self.key.bias torch.Size([768])\n",
      "layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.10.attention.self.value.bias torch.Size([768])\n",
      "layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.10.attention.output.dense.bias torch.Size([768])\n",
      "layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "layer.10.output.dense.bias torch.Size([768])\n",
      "layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.11.attention.self.query.bias torch.Size([768])\n",
      "layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.11.attention.self.key.bias torch.Size([768])\n",
      "layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.11.attention.self.value.bias torch.Size([768])\n",
      "layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.11.attention.output.dense.bias torch.Size([768])\n",
      "layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "layer.11.output.dense.bias torch.Size([768])\n",
      "layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "layer.11.output.LayerNorm.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for k,v in pt_layer.named_parameters():\n",
    "    print(k, v.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
