{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:15:25.164434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-30 16:15:25.164477: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-30 16:15:25.164481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from clu import parameter_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modules needed to be verified\n",
    "\n",
    "\n",
    "## Basic Building Blocks (bb)\n",
    "all the components in the layers file\n",
    "\n",
    "- FlaxBertForSequenceClassification\n",
    "    - FlaxBertForSequenceClassificationModule\n",
    "        - FlaxBertModule\n",
    "            - FlaxBertEmbeddings\n",
    "                - Add\n",
    "                - LayerNorm\n",
    "                - Dropout\n",
    "            - FlaxBertEncoder\n",
    "                - FlaxBertLayerCollection\n",
    "                    - FlaxBertLayer\n",
    "                        - FlaxBertAttention\n",
    "                            - FlaxBertSelfAttention(bb only)\n",
    "                            - FlaxBertSelfOutput(bb only)\n",
    "                        - FlaxBertIntermediate(bb only)\n",
    "                        - FlaxBertOutput(bb only)\n",
    "                    - FlaxBertCheckpointLayer(cond.)\n",
    "            - FlaxBertPooler(bb only)\n",
    "        - Dropout\n",
    "        - Dense"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Building Block verification.\n",
    "- FlaxBertSelfAttention vs.     BertSelfAttention\n",
    "- FlaxBertSelfOutput    vs.     BertSelfOutput\n",
    "- FlaxBertIntermediate  vs.     BertIntermediate\n",
    "- FlaxBertOutput        vs.     BertOutput\n",
    "- FlaxBertPooler        vs.     BertPooler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from bert_torch.BERT import *\n",
    "from bert.modeling_flax_bert import *\n",
    "import bert.modeling_flax_bert as layers\n",
    "from transformers import BertConfig, BertTokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "configuration = BertConfig()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101 7592 2088  999  102]] tensor([[ 101, 7592, 2088,  999,  102]])\n",
      "[0] tensor([0])\n"
     ]
    }
   ],
   "source": [
    "text_batch = [\"Hello world!\"]\n",
    "inputs = tokenizer(text_batch)\n",
    "input_ids = jnp.array(inputs[\"input_ids\"])\n",
    "token_ids = jnp.array(inputs[\"token_type_ids\"])\n",
    "attention_mask = jnp.array(inputs[\"attention_mask\"])\n",
    "position_ids = jnp.arange(input_ids.shape[0])\n",
    "\n",
    "pt_inputs = tokenizer(text_batch, return_tensors='pt')\n",
    "pt_input_ids = pt_inputs[\"input_ids\"]\n",
    "pt_token_ids = pt_inputs[\"token_type_ids\"]\n",
    "pt_attention_mask = pt_inputs[\"attention_mask\"]\n",
    "pt_position_ids = torch.tensor(np.arange(pt_input_ids.shape[0]))\n",
    "\n",
    "print(input_ids, pt_input_ids)\n",
    "print(position_ids, pt_position_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "pt_layer = BertEmbeddings(configuration).eval()\n",
    "f_layer = FlaxBertEmbeddings(configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings.weight torch.Size([30522, 768])\n",
      "position_embeddings.weight torch.Size([512, 768])\n",
      "token_type_embeddings.weight torch.Size([2, 768])\n",
      "LayerNorm.weight torch.Size([768])\n",
      "LayerNorm.bias torch.Size([768])\n",
      "{'params': {'word_embeddings': {'embedding': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.02733476, -0.13386883, -1.1515571 , ..., -0.974222  ,\n",
      "         0.32135013, -1.0175889 ],\n",
      "       [-1.0327494 , -0.3484202 ,  1.3928472 , ...,  0.6928705 ,\n",
      "        -0.36489737,  0.07088251],\n",
      "       ...,\n",
      "       [ 0.5125529 , -0.18763718,  1.4236608 , ..., -1.0472057 ,\n",
      "        -0.1026423 ,  0.14267415],\n",
      "       [ 1.6064404 , -0.9257208 , -1.04948   , ...,  0.23986971,\n",
      "        -0.22128616, -1.3424199 ],\n",
      "       [ 0.9218716 , -0.1787405 ,  0.2866925 , ..., -0.18176642,\n",
      "        -1.4434109 ,  0.78884804]], dtype=float32)}, 'position_embeddings': {'embedding': array([[-0.31082064,  1.4829938 ,  1.1821117 , ..., -1.7082491 ,\n",
      "         0.00952741, -1.2897838 ],\n",
      "       [ 0.2301129 , -1.7007767 , -0.8795543 , ..., -1.4453804 ,\n",
      "        -1.2584949 ,  1.441897  ],\n",
      "       [ 0.4874268 ,  1.6663394 , -1.0212191 , ..., -0.08072364,\n",
      "        -1.7039248 ,  0.33770785],\n",
      "       ...,\n",
      "       [ 0.78157216,  1.3557312 ,  0.38850945, ..., -0.02276304,\n",
      "         1.8053799 , -0.7126273 ],\n",
      "       [ 0.21332154, -1.4165521 , -0.7595579 , ..., -0.8418158 ,\n",
      "         1.5995224 ,  0.7254711 ],\n",
      "       [-1.6350542 ,  0.04837618,  1.3279115 , ...,  0.29517004,\n",
      "         0.94175804, -0.03517431]], dtype=float32)}, 'token_type_embeddings': {'embedding': array([[-1.7558191 , -0.48511395, -1.9814901 , ..., -0.96509707,\n",
      "         0.68763787, -1.1303186 ],\n",
      "       [-2.3470523 ,  1.749061  , -0.44255042, ..., -0.9781201 ,\n",
      "        -1.0659338 ,  0.31134617]], dtype=float32)}, 'LayerNorm': {'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), 'scale': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32)}}}\n"
     ]
    }
   ],
   "source": [
    "for k,v in pt_layer.named_parameters():\n",
    "    print(k, v.shape)\n",
    "\n",
    "vf = {'params':\n",
    "          {'word_embeddings':\n",
    "               {'embedding': None},\n",
    "           'position_embeddings':\n",
    "               {'embedding': None},\n",
    "           'token_type_embeddings':\n",
    "               {'embedding': None},\n",
    "           'LayerNorm':\n",
    "               {'bias': None,\n",
    "                'scale': None},\n",
    "        }\n",
    "      }\n",
    "for k,v in pt_layer.named_parameters():\n",
    "    if k == 'word_embeddings.weight':\n",
    "        vf['params']['word_embeddings']['embedding'] = v.detach().numpy()\n",
    "    if k == 'position_embeddings.weight':\n",
    "        vf['params']['position_embeddings']['embedding'] = v.detach().numpy()\n",
    "    if k == 'token_type_embeddings.weight':\n",
    "        vf['params']['token_type_embeddings']['embedding'] = v.detach().numpy()\n",
    "    if k == 'LayerNorm.weight':\n",
    "        vf['params']['LayerNorm']['scale'] = v.detach().numpy()\n",
    "    if k == 'LayerNorm.bias':\n",
    "        vf['params']['LayerNorm']['bias'] = v.detach().numpy()\n",
    "\n",
    "print(vf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# vf = f_layer.init(jax.random.PRNGKey(0), input_ids, token_ids,  position_ids, attention_mask)\n",
    "f_out = f_layer.apply(vf, input_ids, token_ids, position_ids, attention_mask)\n",
    "pt_out = pt_layer(input_ids=pt_input_ids, token_type_ids=pt_token_ids, position_ids=pt_position_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30522, 768)\n",
      "(1, 5, 768)\n",
      "torch.Size([1, 5, 768])\n",
      "4319.8057\n"
     ]
    }
   ],
   "source": [
    "print(vf['params']['word_embeddings']['embedding'].shape)\n",
    "print(f_out.shape)\n",
    "print(pt_out.shape)\n",
    "print(np.abs(pt_out.detach().numpy() - f_out).sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relprop 2\n",
      "2.5885494\n",
      "2.6496449\n",
      "2.849807\n",
      "1.0\n",
      "1.0\n",
      "(1, 5, 768)\n"
     ]
    }
   ],
   "source": [
    "cam = np.random.rand(*f_out.shape)\n",
    "f_cam = jnp.array( cam / cam.sum())\n",
    "pt_cam = torch.tensor(cam / cam.sum())\n",
    "\n",
    "f_cam1, f_cam2 = f_layer.apply(vf, f_cam, input_ids, token_ids, position_ids, attention_mask, method=f_layer.relprop)\n",
    "kwargs = {'alpha': 1}\n",
    "pt_cam1, pt_cam2 = pt_layer.relprop(pt_cam, **kwargs)\n",
    "\n",
    "\n",
    "print(np.abs(np.array(f_cam1) - pt_cam1.detach().numpy()).sum())\n",
    "print(np.abs(np.array(f_cam2) - pt_cam2.detach().numpy()).sum())\n",
    "print(np.abs(np.array(f_cam1) - pt_cam2.detach().numpy()).sum())\n",
    "print(np.sum(f_cam1) + np.sum(f_cam2))\n",
    "print(np.sum(pt_cam1.detach().numpy()) + np.sum(pt_cam2.detach().numpy()))\n",
    "print(f_cam2.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+--------------+------------+----------+-------+\n",
      "| Name                                   | Shape        | Size       | Mean     | Std   |\n",
      "+----------------------------------------+--------------+------------+----------+-------+\n",
      "| params/LayerNorm/bias                  | (768,)       | 768        | 0.0      | 0.0   |\n",
      "| params/LayerNorm/scale                 | (768,)       | 768        | 1.0      | 0.0   |\n",
      "| params/position_embeddings/embedding   | (512, 768)   | 393,216    | -0.00125 | 0.999 |\n",
      "| params/token_type_embeddings/embedding | (2, 768)     | 1,536      | -0.0142  | 1.01  |\n",
      "| params/word_embeddings/embedding       | (30522, 768) | 23,440,896 | 0.000289 | 1.0   |\n",
      "+----------------------------------------+--------------+------------+----------+-------+\n",
      "Total: 23,837,184\n",
      "BertEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (token_type_embeddings): Embedding(2, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (add1): Add()\n",
      "  (add2): Add()\n",
      ") 23837184\n"
     ]
    }
   ],
   "source": [
    "print(parameter_overview.get_parameter_overview(vf))\n",
    "print(pt_layer, count_parameters(pt_layer))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "pt_layer = BertEncoder(configuration).eval()\n",
    "f_layer = FlaxBertEncoder(configuration)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.0.attention.self.query.bias torch.Size([768])\n",
      "layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.0.attention.self.key.bias torch.Size([768])\n",
      "layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.0.attention.self.value.bias torch.Size([768])\n",
      "layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.0.attention.output.dense.bias torch.Size([768])\n",
      "layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "layer.0.output.dense.bias torch.Size([768])\n",
      "layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.1.attention.self.query.bias torch.Size([768])\n",
      "layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.1.attention.self.key.bias torch.Size([768])\n",
      "layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.1.attention.self.value.bias torch.Size([768])\n",
      "layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.1.attention.output.dense.bias torch.Size([768])\n",
      "layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "layer.1.output.dense.bias torch.Size([768])\n",
      "layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.2.attention.self.query.bias torch.Size([768])\n",
      "layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.2.attention.self.key.bias torch.Size([768])\n",
      "layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.2.attention.self.value.bias torch.Size([768])\n",
      "layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.2.attention.output.dense.bias torch.Size([768])\n",
      "layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "layer.2.output.dense.bias torch.Size([768])\n",
      "layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.3.attention.self.query.bias torch.Size([768])\n",
      "layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.3.attention.self.key.bias torch.Size([768])\n",
      "layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.3.attention.self.value.bias torch.Size([768])\n",
      "layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.3.attention.output.dense.bias torch.Size([768])\n",
      "layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "layer.3.output.dense.bias torch.Size([768])\n",
      "layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.4.attention.self.query.bias torch.Size([768])\n",
      "layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.4.attention.self.key.bias torch.Size([768])\n",
      "layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.4.attention.self.value.bias torch.Size([768])\n",
      "layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.4.attention.output.dense.bias torch.Size([768])\n",
      "layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "layer.4.output.dense.bias torch.Size([768])\n",
      "layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.5.attention.self.query.bias torch.Size([768])\n",
      "layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.5.attention.self.key.bias torch.Size([768])\n",
      "layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.5.attention.self.value.bias torch.Size([768])\n",
      "layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.5.attention.output.dense.bias torch.Size([768])\n",
      "layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "layer.5.output.dense.bias torch.Size([768])\n",
      "layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.6.attention.self.query.bias torch.Size([768])\n",
      "layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.6.attention.self.key.bias torch.Size([768])\n",
      "layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.6.attention.self.value.bias torch.Size([768])\n",
      "layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.6.attention.output.dense.bias torch.Size([768])\n",
      "layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "layer.6.output.dense.bias torch.Size([768])\n",
      "layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.7.attention.self.query.bias torch.Size([768])\n",
      "layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.7.attention.self.key.bias torch.Size([768])\n",
      "layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.7.attention.self.value.bias torch.Size([768])\n",
      "layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.7.attention.output.dense.bias torch.Size([768])\n",
      "layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "layer.7.output.dense.bias torch.Size([768])\n",
      "layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.8.attention.self.query.bias torch.Size([768])\n",
      "layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.8.attention.self.key.bias torch.Size([768])\n",
      "layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.8.attention.self.value.bias torch.Size([768])\n",
      "layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.8.attention.output.dense.bias torch.Size([768])\n",
      "layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "layer.8.output.dense.bias torch.Size([768])\n",
      "layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.9.attention.self.query.bias torch.Size([768])\n",
      "layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.9.attention.self.key.bias torch.Size([768])\n",
      "layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.9.attention.self.value.bias torch.Size([768])\n",
      "layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.9.attention.output.dense.bias torch.Size([768])\n",
      "layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "layer.9.output.dense.bias torch.Size([768])\n",
      "layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.10.attention.self.query.bias torch.Size([768])\n",
      "layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.10.attention.self.key.bias torch.Size([768])\n",
      "layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.10.attention.self.value.bias torch.Size([768])\n",
      "layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.10.attention.output.dense.bias torch.Size([768])\n",
      "layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "layer.10.output.dense.bias torch.Size([768])\n",
      "layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "layer.11.attention.self.query.bias torch.Size([768])\n",
      "layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "layer.11.attention.self.key.bias torch.Size([768])\n",
      "layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "layer.11.attention.self.value.bias torch.Size([768])\n",
      "layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "layer.11.attention.output.dense.bias torch.Size([768])\n",
      "layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "layer.11.output.dense.bias torch.Size([768])\n",
      "layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "layer.11.output.LayerNorm.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for k,v in pt_layer.named_parameters():\n",
    "    print(k, v.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
